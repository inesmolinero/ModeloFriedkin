{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f043f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rutas\n",
    "data_path = Path(\"data\")\n",
    "input_file = data_path / \"Twitter_Data.csv\"\n",
    "output_scores = data_path / \"Twitter_Data_scores.csv\"\n",
    "output_sample = data_path / \"Twitter_Data_sample300.csv\"\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv(\"data/Twitter_Data.csv\")\n",
    "\n",
    "# Inicializar el analizador de sentimiento\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Limpiar y analizar sentimiento\n",
    "def calcular_sentimiento(texto):\n",
    "    if pd.isna(texto) or texto.strip() == \"\":\n",
    "        return None\n",
    "    puntuacion = analyzer.polarity_scores(texto)\n",
    "    return puntuacion[\"compound\"]\n",
    "\n",
    "df[\"sentimiento\"] = df[\"clean_text\"].apply(calcular_sentimiento)\n",
    "\n",
    "# Quitar filas nulas\n",
    "df = df.dropna(subset=[\"sentimiento\"])\n",
    "\n",
    "# Convertir de escala [-1,1] a [0 ,1]\n",
    "df[\"sentimiento_escalado\"] = (df[\"sentimiento\"] + 1) / 2\n",
    "\n",
    "# Guardar todos los scores\n",
    "df[[\"sentimiento_escalado\"]].to_csv(\"data/Twitter_Data_scores.csv\", index=False)\n",
    "\n",
    "# Crear muestra estratificada de 300 tweets (diviendo en deciles)\n",
    "n_muestra= 300\n",
    "df[\"decil\"] = pd.qcut(df[\"sentimiento\"], q=10, labels=False, duplicates=\"drop\")\n",
    "\n",
    "# Sacar 30 tweets de cada grupo \n",
    "opiniones_objetivo_por_decil = int(n_muestra/ 10)\n",
    "\n",
    "muestra = (\n",
    "    df\n",
    "    .groupby(\"decil\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(30, len(x)), random_state=9),\n",
    "    include_groups=False)\n",
    ")\n",
    "# Si no llegamos a 300, rellenamos con tweets aleatorios\n",
    "if len(muestra) < 300:\n",
    "    faltan = 300 - len(muestra)\n",
    "    resto = df[~df.index.isin(muestra.index)]\n",
    "    extra = resto.sample(n=min(faltan, len(resto)), random_state=9)\n",
    "    muestra = pd.concat([muestra, extra], ignore_index=True)\n",
    "\n",
    "# Guardar muestra \n",
    "muestra[[\"clean_text\", \"sentimiento\", \"sentimiento_escalado\"]].to_csv(\n",
    "    \"data/Twitter_Data_sample300.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Total de opiniones: {len(df)}\")\n",
    "print(f\" Total de muestra: {len(muestra)}\")\n",
    "\n",
    "# Comprobación de muestra estratificada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(muestra[\"sentimiento\"], bins=50, color='#B39DDB' , edgecolor='purple')\n",
    "plt.xlabel('Sentimiento de la muestra de 300 opiniones ')\n",
    "plt.ylabel('Cantidad de tweets')\n",
    "plt.title('Distribución de sentimiento')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df[\"sentimiento\"], bins=50, color='#B39DDB',  edgecolor='purple')\n",
    "plt.xlabel('Sentimiento del total de opiniones')\n",
    "plt.ylabel('Cantidad de tweets')\n",
    "plt.title('Distribución de sentimiento')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "\n",
    "##\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Muestra\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(muestra[\"sentimiento_escalado\"], bins=50, color='#B39DDB')\n",
    "plt.xlabel('Sentimiento')\n",
    "plt.ylabel('Cantidad de tweets')\n",
    "plt.title('Muestra (300)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Total\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df[\"sentimiento_escalado\"], bins=50, color='#B39DDB')\n",
    "plt.xlabel('Sentimiento')\n",
    "plt.ylabel('Cantidad de tweets')\n",
    "plt.title('Total')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b077fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decil\n",
       "(0.0018, 0.188]    16616\n",
       "(0.188, 0.309]     16750\n",
       "(0.309, 0.461]     16192\n",
       "(0.461, 0.5]       35445\n",
       "(0.5, 0.625]       12958\n",
       "(0.625, 0.711]     17635\n",
       "(0.711, 0.793]     15205\n",
       "(0.793, 0.879]     16144\n",
       "(0.879, 0.996]     16030\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"decil\"].value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModeloFriedkin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
