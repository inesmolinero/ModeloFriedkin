"""
An√°lisis Estad√≠stico y Visualizaci√≥n de Experimentos Friedkin-Johnsen

Este script realiza:
1. Carga y limpieza de datos
2. An√°lisis exploratorio de datos (EDA)
3. Tests de hip√≥tesis estad√≠sticas
4. Visualizaciones comprehensivas
5. Generaci√≥n de informe autom√°tico

Autor: An√°lisis mejorado
Fecha: Noviembre 2024
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
from scipy.io import loadmat
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12

#==============================================================================
# SECCI√ìN 1: CONFIGURACI√ìN Y CARGA DE DATOS
#==============================================================================

class FriedkinAnalyzer:
    """Clase principal para an√°lisis de experimentos Friedkin-Johnsen"""
    
    def __init__(self, results_dir):
        """
        Inicializa el analizador con el directorio de resultados
        
        Args:
            results_dir: Ruta al directorio resultados_YYYY-MM-DD_HHMMSS
        """
        self.results_dir = Path(results_dir)
        self.output_dir = self.results_dir / 'analysis'
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"üìÇ Directorio de resultados: {self.results_dir}")
        print(f"üìä An√°lisis se guardar√° en: {self.output_dir}\n")
        
        # Cargar datos
        self.df = self.load_data()
        self.prepare_data()
        
    def load_data(self):
        """Carga el CSV de m√©tricas agregadas"""
        csv_path = self.results_dir / 'summary_metrics_AGG.csv'
        
        if not csv_path.exists():
            raise FileNotFoundError(f"No se encuentra: {csv_path}")
        
        df = pd.read_csv(csv_path)
        print(f"‚úì Cargados {len(df)} escenarios")
        print(f"‚úì Variables: {len(df.columns)} columnas\n")
        
        return df
    
    def prepare_data(self):
        """Prepara y limpia los datos para an√°lisis"""
        # Crear variables categ√≥ricas ordenadas
        self.df['regimen_cat'] = pd.Categorical(
            self.df['regimen'], 
            categories=['desconectada', 'umbral', 'fuerte'],
            ordered=True
        )
        
        self.df['loc_cat'] = pd.Categorical(
            self.df['loc'],
            categories=['low', 'mid', 'high'],
            ordered=True
        )
        
        # Crear variable de proporci√≥n de trolls categ√≥rica
        self.df['trolls_pct'] = self.df['fracTrolls'] * 100
        self.df['trolls_cat'] = pd.cut(
            self.df['trolls_pct'],
            bins=[-0.1, 0.1, 15, 25, 35],
            labels=['0%', '10%', '20%', '30%']
        )
        
        # Variables de inter√©s principales
        self.outcome_vars = [
            'mean_rangoFinal', 'mean_stdFinal', 'mean_convTime',
            'mean_NDI', 'mean_P2', 'mean_P4',
            'prop_consenso', 'mean_rho_LW'
        ]
        
        print("‚úì Datos preparados\n")

#==============================================================================
# SECCI√ìN 2: AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)
#==============================================================================

    def exploratory_analysis(self):
        """Realiza an√°lisis exploratorio completo"""
        print("="*70)
        print("AN√ÅLISIS EXPLORATORIO DE DATOS")
        print("="*70 + "\n")
        
        # Estad√≠sticos descriptivos por r√©gimen
        print("üìä Estad√≠sticos Descriptivos por R√©gimen de Red\n")
        desc_by_regime = self.df.groupby('regimen')[self.outcome_vars].agg(['mean', 'std', 'min', 'max'])
        print(desc_by_regime.round(4))
        print("\n" + "-"*70 + "\n")
        
        # Estad√≠sticos por proporci√≥n de trolls
        print("üìä Estad√≠sticos Descriptivos por Proporci√≥n de Trolls\n")
        desc_by_trolls = self.df.groupby('trolls_cat')[self.outcome_vars].agg(['mean', 'std'])
        print(desc_by_trolls.round(4))
        print("\n" + "-"*70 + "\n")
        
        # Correlaciones
        print("üìä Matriz de Correlaciones entre Variables Clave\n")
        corr_matrix = self.df[self.outcome_vars].corr()
        print(corr_matrix.round(3))
        print("\n")
        
        # Guardar resultados
        with open(self.output_dir / 'descriptive_stats.txt', 'w') as f:
            f.write("ESTAD√çSTICOS DESCRIPTIVOS - Experimentos Friedkin-Johnsen\n")
            f.write("="*70 + "\n\n")
            f.write("Por R√©gimen de Red:\n")
            f.write(desc_by_regime.to_string())
            f.write("\n\n" + "-"*70 + "\n\n")
            f.write("Por Proporci√≥n de Trolls:\n")
            f.write(desc_by_trolls.to_string())
            f.write("\n\n" + "-"*70 + "\n\n")
            f.write("Matriz de Correlaciones:\n")
            f.write(corr_matrix.to_string())
        
        return desc_by_regime, desc_by_trolls, corr_matrix

#==============================================================================
# SECCI√ìN 3: TESTS DE HIP√ìTESIS
#==============================================================================

    def hypothesis_tests(self):
        """Realiza tests de hip√≥tesis estad√≠sticas"""
        print("="*70)
        print("TESTS DE HIP√ìTESIS ESTAD√çSTICAS")
        print("="*70 + "\n")
        
        results = {}
        
        # H1: El r√©gimen de conectividad afecta la polarizaci√≥n (NDI)
        print("H1: ¬øEl r√©gimen de red afecta la polarizaci√≥n (NDI)?")
        print("-" * 60)
        h1_result = self._test_regime_effect('mean_NDI')
        results['H1_regime_polarization'] = h1_result
        print()
        
        # H2: Mayor proporci√≥n de trolls aumenta polarizaci√≥n
        print("H2: ¬øMayor proporci√≥n de trolls aumenta la polarizaci√≥n?")
        print("-" * 60)
        h2_result = self._test_trolls_correlation('mean_NDI')
        results['H2_trolls_polarization'] = h2_result
        print()
        
        # H3: Lambda (susceptibilidad) afecta convergencia
        print("H3: ¬øLambda afecta el tiempo de convergencia?")
        print("-" * 60)
        h3_result = self._test_lambda_effect('mean_convTime')
        results['H3_lambda_convergence'] = h3_result
        print()
        
        # H4: Centralidad de trolls afecta influencia
        print("H4: ¬øLa ubicaci√≥n de trolls (centralidad) afecta el rango final?")
        print("-" * 60)
        h4_result = self._test_location_effect('mean_rangoFinal')
        results['H4_location_influence'] = h4_result
        print()
        
        # H5: Interacci√≥n r√©gimen x trolls
        print("H5: ¬øExiste interacci√≥n entre r√©gimen y proporci√≥n de trolls?")
        print("-" * 60)
        h5_result = self._test_interaction('mean_NDI')
        results['H5_interaction'] = h5_result
        print()
        
        # H6: Probabilidad frontera vs polarizaci√≥n
        print("H6: ¬øMayor contacto normales-trolls aumenta polarizaci√≥n?")
        print("-" * 60)
        h6_result = self._test_boundary_effect('mean_P_norm_vs_trolls', 'mean_NDI')
        results['H6_boundary_polarization'] = h6_result
        print()
        
        # Guardar resultados
        self._save_hypothesis_results(results)
        
        return results
    
    def _test_regime_effect(self, outcome_var):
        """ANOVA para efecto del r√©gimen"""
        groups = [self.df[self.df['regimen'] == r][outcome_var].dropna() 
                  for r in ['desconectada', 'umbral', 'fuerte']]
        
        # Eliminar grupos vac√≠os
        groups = [g for g in groups if len(g) > 0]
        
        if len(groups) < 2:
            print("‚ö†Ô∏è  Datos insuficientes para ANOVA")
            return {'test': 'ANOVA', 'F': np.nan, 'p_value': np.nan, 'significant': False}
        
        F_stat, p_value = stats.f_oneway(*groups)
        
        # Medias por grupo
        means = {r: self.df[self.df['regimen'] == r][outcome_var].mean() 
                 for r in ['desconectada', 'umbral', 'fuerte']}
        
        print(f"  ANOVA: F = {F_stat:.4f}, p = {p_value:.4f}")
        print(f"  Medias por r√©gimen: {means}")
        
        if p_value < 0.05:
            print("  ‚úì Efecto significativo (p < 0.05)")
            significant = True
        else:
            print("  ‚úó No significativo (p ‚â• 0.05)")
            significant = False
        
        return {
            'test': 'ANOVA',
            'F': F_stat,
            'p_value': p_value,
            'significant': significant,
            'means': means
        }
    
    def _test_trolls_correlation(self, outcome_var):
        """Correlaci√≥n de Spearman: trolls vs polarizaci√≥n"""
        data = self.df[['fracTrolls', outcome_var]].dropna()
        
        if len(data) < 3:
            print("‚ö†Ô∏è  Datos insuficientes para correlaci√≥n")
            return {'test': 'Spearman', 'rho': np.nan, 'p_value': np.nan, 'significant': False}
        
        rho, p_value = stats.spearmanr(data['fracTrolls'], data[outcome_var])
        
        print(f"  Spearman œÅ = {rho:.4f}, p = {p_value:.4f}")
        
        if p_value < 0.05:
            direction = "positiva" if rho > 0 else "negativa"
            print(f"  ‚úì Correlaci√≥n {direction} significativa (p < 0.05)")
            significant = True
        else:
            print("  ‚úó No significativo (p ‚â• 0.05)")
            significant = False
        
        return {
            'test': 'Spearman',
            'rho': rho,
            'p_value': p_value,
            'significant': significant
        }
    
    def _test_lambda_effect(self, outcome_var):
        """Correlaci√≥n: lambda vs tiempo de convergencia"""
        data = self.df[['lam', outcome_var]].dropna()
        
        if len(data) < 3:
            print("‚ö†Ô∏è  Datos insuficientes")
            return {'test': 'Pearson', 'r': np.nan, 'p_value': np.nan, 'significant': False}
        
        r, p_value = stats.pearsonr(data['lam'], data[outcome_var])
        
        print(f"  Pearson r = {r:.4f}, p = {p_value:.4f}")
        
        if p_value < 0.05:
            direction = "positiva" if r > 0 else "negativa"
            print(f"  ‚úì Correlaci√≥n {direction} significativa (p < 0.05)")
            significant = True
        else:
            print("  ‚úó No significativo (p ‚â• 0.05)")
            significant = False
        
        return {
            'test': 'Pearson',
            'r': r,
            'p_value': p_value,
            'significant': significant
        }
    
    def _test_location_effect(self, outcome_var):
        """ANOVA: ubicaci√≥n de trolls vs influencia"""
        # Filtrar solo escenarios con trolls
        data_with_trolls = self.df[self.df['trolls'] > 0]
        
        if len(data_with_trolls) == 0:
            print("‚ö†Ô∏è  No hay escenarios con trolls")
            return {'test': 'ANOVA', 'F': np.nan, 'p_value': np.nan, 'significant': False}
        
        groups = [data_with_trolls[data_with_trolls['loc'] == loc][outcome_var].dropna()
                  for loc in ['low', 'mid', 'high']]
        
        groups = [g for g in groups if len(g) > 0]
        
        if len(groups) < 2:
            print("‚ö†Ô∏è  Datos insuficientes")
            return {'test': 'ANOVA', 'F': np.nan, 'p_value': np.nan, 'significant': False}
        
        F_stat, p_value = stats.f_oneway(*groups)
        
        means = {loc: data_with_trolls[data_with_trolls['loc'] == loc][outcome_var].mean()
                 for loc in ['low', 'mid', 'high']}
        
        print(f"  ANOVA: F = {F_stat:.4f}, p = {p_value:.4f}")
        print(f"  Medias por ubicaci√≥n: {means}")
        
        if p_value < 0.05:
            print("  ‚úì Efecto significativo (p < 0.05)")
            significant = True
        else:
            print("  ‚úó No significativo (p ‚â• 0.05)")
            significant = False
        
        return {
            'test': 'ANOVA',
            'F': F_stat,
            'p_value': p_value,
            'significant': significant,
            'means': means
        }
    
    def _test_interaction(self, outcome_var):
        """Test de interacci√≥n: r√©gimen x trolls (ANOVA two-way simplificado)"""
        # Preparar datos
        data = self.df[['regimen', 'trolls_cat', outcome_var]].dropna()
        
        if len(data) < 10:
            print("‚ö†Ô∏è  Datos insuficientes para test de interacci√≥n")
            return {'test': 'Two-way ANOVA', 'interaction_p': np.nan, 'significant': False}
        
        # Crear grupos para cada combinaci√≥n
        interaction_means = data.groupby(['regimen', 'trolls_cat'])[outcome_var].mean()
        
        print(f"  Medias por r√©gimen x trolls:")
        print(interaction_means.unstack(fill_value=np.nan).round(4))
        
        # Test simplificado: comparar varianza entre vs dentro grupos
        grand_mean = data[outcome_var].mean()
        
        # Varianza explicada por interacci√≥n (aproximada)
        ss_interaction = 0
        for (reg, troll), group_data in data.groupby(['regimen', 'trolls_cat']):
            group_mean = group_data[outcome_var].mean()
            n = len(group_data)
            ss_interaction += n * (group_mean - grand_mean)**2
        
        ss_total = np.sum((data[outcome_var] - grand_mean)**2)
        
        if ss_total > 0:
            eta_squared = ss_interaction / ss_total
            print(f"  Œ∑¬≤ (efecto) = {eta_squared:.4f}")
            
            # Heur√≠stica: interacci√≥n fuerte si Œ∑¬≤ > 0.10
            if eta_squared > 0.10:
                print("  ‚úì Interacci√≥n aparente fuerte (Œ∑¬≤ > 0.10)")
                significant = True
            else:
                print("  ‚úó Interacci√≥n d√©bil (Œ∑¬≤ ‚â§ 0.10)")
                significant = False
        else:
            eta_squared = 0
            significant = False
        
        return {
            'test': 'Two-way ANOVA (simplified)',
            'eta_squared': eta_squared,
            'significant': significant,
            'means': interaction_means.to_dict()
        }
    
    def _test_boundary_effect(self, predictor_var, outcome_var):
        """Correlaci√≥n: probabilidad frontera vs polarizaci√≥n"""
        data = self.df[[predictor_var, outcome_var]].dropna()
        
        if len(data) < 3:
            print("‚ö†Ô∏è  Datos insuficientes")
            return {'test': 'Spearman', 'rho': np.nan, 'p_value': np.nan, 'significant': False}
        
        rho, p_value = stats.spearmanr(data[predictor_var], data[outcome_var])
        
        print(f"  Spearman œÅ = {rho:.4f}, p = {p_value:.4f}")
        
        if p_value < 0.05:
            direction = "positiva" if rho > 0 else "negativa"
            print(f"  ‚úì Correlaci√≥n {direction} significativa (p < 0.05)")
            significant = True
        else:
            print("  ‚úó No significativo (p ‚â• 0.05)")
            significant = False
        
        return {
            'test': 'Spearman',
            'rho': rho,
            'p_value': p_value,
            'significant': significant
        }
    
    def _save_hypothesis_results(self, results):
        """Guarda resultados de tests de hip√≥tesis"""
        with open(self.output_dir / 'hypothesis_tests.txt', 'w') as f:
            f.write("TESTS DE HIP√ìTESIS - Experimentos Friedkin-Johnsen\n")
            f.write("="*70 + "\n\n")
            
            for hypothesis, result in results.items():
                f.write(f"{hypothesis}:\n")
                f.write(f"  Test: {result['test']}\n")
                
                for key, value in result.items():
                    if key != 'test':
                        f.write(f"  {key}: {value}\n")
                
                f.write("\n" + "-"*70 + "\n\n")
        
        print(f"‚úì Resultados guardados en: {self.output_dir / 'hypothesis_tests.txt'}\n")

# #==============================================================================
# # SECCI√ìN 4: VISUALIZACIONES
# #==============================================================================

#     def create_all_plots(self):
#         """Genera todas las visualizaciones"""
#         print("="*70)
#         print("GENERACI√ìN DE VISUALIZACIONES")
#         print("="*70 + "\n")
        
#         # 1. Efectos principales
#         self.plot_main_effects()
        
#         # 2. Interacciones
#         self.plot_interactions()
        
#         # 3. Polarizaci√≥n
#         self.plot_polarization_metrics()
        
#         # 4. Convergencia
#         self.plot_convergence_analysis()
        
#         # 5. Propiedades de red
#         self.plot_network_properties()
        
#         # 6. Heatmaps
#         self.plot_heatmaps()
        
#         # 7. Correlaciones
#         self.plot_correlation_matrix()
        
#         print("\n‚úì Todas las visualizaciones generadas\n")
    
#     def plot_main_effects(self):
#         """Gr√°ficos de efectos principales"""
#         print("üìà Generando gr√°ficos de efectos principales...")
        
#         fig, axes = plt.subplots(2, 2, figsize=(16, 12))
#         fig.suptitle('Efectos Principales sobre Polarizaci√≥n (NDI)', fontsize=16, fontweight='bold')
        
#         # 1. R√©gimen de red
#         ax = axes[0, 0]
#         sns.boxplot(data=self.df, x='regimen_cat', y='mean_NDI', ax=ax, palette='Set2')
#         ax.set_title('A) Efecto del R√©gimen de Red')
#         ax.set_xlabel('R√©gimen de Conectividad')
#         ax.set_ylabel('Polarizaci√≥n (NDI)')
#         ax.grid(True, alpha=0.3)
        
#         # 2. Proporci√≥n de trolls
#         ax = axes[0, 1]
#         sns.violinplot(data=self.df, x='trolls_cat', y='mean_NDI', ax=ax, palette='Set3')
#         ax.set_title('B) Efecto de Proporci√≥n de Trolls')
#         ax.set_xlabel('Proporci√≥n de Trolls (%)')
#         ax.set_ylabel('Polarizaci√≥n (NDI)')
#         ax.grid(True, alpha=0.3)
        
#         # 3. Lambda (susceptibilidad)
#         ax = axes[1, 0]
#         for regime in ['desconectada', 'umbral', 'fuerte']:
#             data = self.df[self.df['regimen'] == regime]
#             ax.scatter(data['lam'], data['mean_NDI'], label=regime, alpha=0.6, s=50)
#         ax.set_title('C) Efecto de Susceptibilidad (Œª)')
#         ax.set_xlabel('Lambda (Œª)')
#         ax.set_ylabel('Polarizaci√≥n (NDI)')
#         ax.legend(title='R√©gimen')
#         ax.grid(True, alpha=0.3)
        
#         # 4. Ubicaci√≥n de trolls
#         ax = axes[1, 1]
#         data_with_trolls = self.df[self.df['trolls'] > 0]
#         if len(data_with_trolls) > 0:
#             sns.boxplot(data=data_with_trolls, x='loc_cat', y='mean_NDI', ax=ax)
#             ax.set_title('D) Efecto de Ubicaci√≥n de Trolls')
#             ax.set_xlabel('Banda de Centralidad')
#             ax.set_ylabel('Polarizaci√≥n (NDI)')
#             ax.grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'main_effects.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: main_effects.png")
    
#     def plot_interactions(self):
#         """Gr√°ficos de interacciones"""
#         print("üìà Generando gr√°ficos de interacciones...")
        
#         fig, axes = plt.subplots(1, 2, figsize=(16, 6))
#         fig.suptitle('Interacciones entre Factores', fontsize=16, fontweight='bold')
        
#         # 1. R√©gimen x Trolls
#         ax = axes[0]
#         for regime in ['desconectada', 'umbral', 'fuerte']:
#             data = self.df[self.df['regimen'] == regime]
#             means = data.groupby('trolls_pct')['mean_NDI'].mean()
#             ax.plot(means.index, means.values, marker='o', linewidth=2, markersize=8, label=regime)
        
#         ax.set_title('A) R√©gimen √ó Proporci√≥n de Trolls')
#         ax.set_xlabel('Proporci√≥n de Trolls (%)')
#         ax.set_ylabel('Polarizaci√≥n Media (NDI)')
#         ax.legend(title='R√©gimen')
#         ax.grid(True, alpha=0.3)
        
#         # 2. Lambda x Trolls
#         ax = axes[1]
#         for trolls_cat in ['0%', '10%', '20%', '30%']:
#             data = self.df[self.df['trolls_cat'] == trolls_cat]
#             if len(data) > 0:
#                 means = data.groupby('lam')['mean_NDI'].mean()
#                 ax.plot(means.index, means.values, marker='s', linewidth=2, markersize=8, label=trolls_cat)
        
#         ax.set_title('B) Lambda √ó Proporci√≥n de Trolls')
#         ax.set_xlabel('Lambda (Œª)')
#         ax.set_ylabel('Polarizaci√≥n Media (NDI)')
#         ax.legend(title='Trolls')
#         ax.grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'interactions.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: interactions.png")
    
#     def plot_polarization_metrics(self):
#         """Comparaci√≥n de m√©tricas de polarizaci√≥n"""
#         print("üìà Generando gr√°ficos de m√©tricas de polarizaci√≥n...")
        
#         fig, axes = plt.subplots(2, 2, figsize=(16, 12))
#         fig.suptitle('M√©tricas de Polarizaci√≥n', fontsize=16, fontweight='bold')
        
#         # NDI por r√©gimen y trolls
#         ax = axes[0, 0]
#         pivot_ndi = self.df.pivot_table(values='mean_NDI', index='regimen_cat', columns='trolls_cat')
#         sns.heatmap(pivot_ndi, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'NDI'})
#         ax.set_title('A) NDI: Network Disagreement Index')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         # P2 por r√©gimen y trolls
#         ax = axes[0, 1]
#         pivot_p2 = self.df.pivot_table(values='mean_P2', index='regimen_cat', columns='trolls_cat')
#         sns.heatmap(pivot_p2, annot=True, fmt='.3f', cmap='RdPu', ax=ax, cbar_kws={'label': 'P2'})
#         ax.set_title('B) P2: Energ√≠a Media')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         # P4 por r√©gimen y trolls
#         ax = axes[1, 0]
#         pivot_p4 = self.df.pivot_table(values='mean_P4', index='regimen_cat', columns='trolls_cat')
#         sns.heatmap(pivot_p4, annot=True, fmt='.1f', cmap='Blues', ax=ax, cbar_kws={'label': 'P4'})
#         ax.set_title('C) P4: Extremismo Absoluto')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         # Comparaci√≥n de m√©tricas normalizadas
#         ax = axes[1, 1]
#         metrics = ['mean_NDI', 'mean_P2', 'mean_P4']
#         df_norm = self.df[metrics].apply(lambda x: (x - x.min()) / (x.max() - x.min()))
#         df_norm.columns = ['NDI (norm)', 'P2 (norm)', 'P4 (norm)']
#         df_norm.boxplot(ax=ax, patch_artist=True)
#         ax.set_title('D) Comparaci√≥n de M√©tricas (Normalizadas)')
#         ax.set_ylabel('Valor Normalizado [0,1]')
#         ax.grid(True, alpha=0.3)
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'polarization_metrics.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: polarization_metrics.png")
    
#     def plot_convergence_analysis(self):
#         """An√°lisis de convergencia"""
#         print("üìà Generando gr√°ficos de convergencia...")
        
#         fig, axes = plt.subplots(2, 2, figsize=(16, 12))
#         fig.suptitle('An√°lisis de Convergencia', fontsize=16, fontweight='bold')
        
#         # 1. Tiempo de convergencia vs lambda
#         ax = axes[0, 0]
#         for regime in ['desconectada', 'umbral', 'fuerte']:
#             data = self.df[self.df['regimen'] == regime]
#             ax.scatter(data['lam'], data['mean_convTime'], label=regime, alpha=0.6, s=50)
#         ax.set_title('A) Tiempo de Convergencia vs Lambda')
#         ax.set_xlabel('Lambda (Œª)')
#         ax.set_ylabel('Tiempo Medio de Convergencia')
#         ax.legend(title='R√©gimen')
#         ax.grid(True, alpha=0.3)
        
#         # 2. Radio espectral vs convergencia
#         ax = axes[0, 1]
#         ax.scatter(self.df['mean_rho_LW'], self.df['mean_convTime'], alpha=0.6, s=50, c=self.df['trolls_pct'], cmap='viridis')
#         ax.set_title('B) Radio Espectral vs Convergencia')
#         ax.set_xlabel('Radio Espectral œÅ(ŒõW)')
#         ax.set_ylabel('Tiempo Medio de Convergencia')
#         cbar = plt.colorbar(ax.collections[0], ax=ax)
#         cbar.set_label('% Trolls')
#         ax.grid(True, alpha=0.3)
        
#         # 3. Proporci√≥n de consenso por r√©gimen
#         ax = axes[1, 0]
#         consensus_data = self.df.groupby(['regimen_cat', 'trolls_cat'])['prop_consenso'].mean().unstack()
#         consensus_data.plot(kind='bar', ax=ax, width=0.8, colormap='tab10')
#         ax.set_title('C) Proporci√≥n de Consenso')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('Proporci√≥n de Consenso')
#         ax.legend(title='% Trolls', bbox_to_anchor=(1.05, 1))
#         ax.grid(True, alpha=0.3, axis='y')
#         plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)
        
#         # 4. Distribuci√≥n de tiempo de convergencia
#         ax = axes[1, 1]
#         for regime in ['desconectada', 'umbral', 'fuerte']:
#             data = self.df[self.df['regimen'] == regime]['mean_convTime'].dropna()
#             if len(data) > 0:
#                 ax.hist(data, alpha=0.6, bins=20, label=regime, edgecolor='black')
#         ax.set_title('D) Distribuci√≥n de Tiempo de Convergencia')
#         ax.set_xlabel('Tiempo de Convergencia')
#         ax.set_ylabel('Frecuencia')
#         ax.legend(title='R√©gimen')
#         ax.grid(True, alpha=0.3, axis='y')
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'convergence_analysis.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: convergence_analysis.png")
    
#     def plot_network_properties(self):
#         """Propiedades de las redes"""
#         print("üìà Generando gr√°ficos de propiedades de red...")
        
#         fig, axes = plt.subplots(2, 3, figsize=(18, 12))
#         fig.suptitle('Propiedades de las Redes', fontsize=16, fontweight='bold')
        
#         # 1. Componentes fuertemente conexas (W)
#         ax = axes[0, 0]
#         sns.boxplot(data=self.df, x='regimen_cat', y='mean_nSCC_W', ax=ax, palette='Set2')
#         ax.set_title('A) SCCs en W')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('N√∫mero de SCCs')
#         ax.grid(True, alpha=0.3, axis='y')
        
#         # 2. Componentes fuertemente conexas (ŒõW)
#         ax = axes[0, 1]
#         sns.boxplot(data=self.df, x='regimen_cat', y='mean_nSCC_LW', ax=ax, palette='Set3')
#         ax.set_title('B) SCCs en ŒõW')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('N√∫mero de SCCs')
#         ax.grid(True, alpha=0.3, axis='y')
        
#         # 3. Proporci√≥n fuertemente conexa
#         ax = axes[0, 2]
#         strong_data = self.df.groupby('regimen_cat')[['prop_isStrongW', 'prop_isStrongLW']].mean()
#         strong_data.plot(kind='bar', ax=ax, width=0.8)
#         ax.set_title('C) Proporci√≥n Fuertemente Conexa')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('Proporci√≥n')
#         ax.legend(['W', 'ŒõW'])
#         ax.grid(True, alpha=0.3, axis='y')
#         plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)
        
#         # 4. Radio espectral W vs ŒõW
#         ax = axes[1, 0]
#         ax.scatter(self.df['mean_rho_W'], self.df['mean_rho_LW'], 
#                    c=self.df['trolls_pct'], cmap='plasma', alpha=0.6, s=50)
#         ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='y=x')
#         ax.set_title('D) Radio Espectral: W vs ŒõW')
#         ax.set_xlabel('œÅ(W)')
#         ax.set_ylabel('œÅ(ŒõW)')
#         ax.legend()
#         ax.grid(True, alpha=0.3)
#         cbar = plt.colorbar(ax.collections[0], ax=ax)
#         cbar.set_label('% Trolls')
        
#         # 5. Per√≠odo por r√©gimen
#         ax = axes[1, 1]
#         period_data = self.df.groupby('regimen_cat')[['mean_periodW', 'mean_periodLW']].mean()
#         period_data.plot(kind='bar', ax=ax, width=0.8)
#         ax.set_title('E) Per√≠odo Medio de Grafos')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('Per√≠odo')
#         ax.legend(['W', 'ŒõW'])
#         ax.grid(True, alpha=0.3, axis='y')
#         plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)
        
#         # 6. Proporci√≥n primitiva (ŒõW)
#         ax = axes[1, 2]
#         prim_data = self.df.groupby(['regimen_cat', 'trolls_cat'])['prop_isPrimLW'].mean().unstack()
#         prim_data.plot(kind='bar', ax=ax, width=0.8, colormap='Spectral')
#         ax.set_title('F) Proporci√≥n de Grafos Primitivos (ŒõW)')
#         ax.set_xlabel('R√©gimen')
#         ax.set_ylabel('Proporci√≥n Primitiva')
#         ax.legend(title='% Trolls', bbox_to_anchor=(1.05, 1))
#         ax.grid(True, alpha=0.3, axis='y')
#         plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'network_properties.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: network_properties.png")
    
#     def plot_heatmaps(self):
#         """Heatmaps de resultados clave"""
#         print("üìà Generando heatmaps...")
        
#         fig, axes = plt.subplots(2, 2, figsize=(16, 14))
#         fig.suptitle('Heatmaps: R√©gimen √ó Trolls', fontsize=16, fontweight='bold')
        
#         # 1. Rango final
#         ax = axes[0, 0]
#         pivot = self.df.pivot_table(values='mean_rangoFinal', 
#                                      index='regimen_cat', 
#                                      columns='trolls_cat')
#         sns.heatmap(pivot, annot=True, fmt='.3f', cmap='RdYlGn_r', ax=ax,
#                     cbar_kws={'label': 'Rango Final'})
#         ax.set_title('A) Rango Final de Opiniones')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         # 2. Desviaci√≥n est√°ndar final
#         ax = axes[0, 1]
#         pivot = self.df.pivot_table(values='mean_stdFinal', 
#                                      index='regimen_cat', 
#                                      columns='trolls_cat')
#         sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrBr', ax=ax,
#                     cbar_kws={'label': 'Std Final'})
#         ax.set_title('B) Desviaci√≥n Est√°ndar Final')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         # 3. Probabilidad frontera normales-trolls
#         ax = axes[1, 0]
#         data_with_trolls = self.df[self.df['trolls'] > 0]
#         if len(data_with_trolls) > 0:
#             pivot = data_with_trolls.pivot_table(values='mean_P_norm_vs_trolls',
#                                                  index='regimen_cat',
#                                                  columns='trolls_cat')
#             sns.heatmap(pivot, annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
#                         cbar_kws={'label': 'P(N‚ÜíT)'})
#             ax.set_title('C) Probabilidad Frontera Normales‚ÜíTrolls')
#             ax.set_xlabel('Proporci√≥n de Trolls')
#             ax.set_ylabel('R√©gimen')
        
#         # 4. Radio espectral ŒõW
#         ax = axes[1, 1]
#         pivot = self.df.pivot_table(values='mean_rho_LW',
#                                      index='regimen_cat',
#                                      columns='trolls_cat')
#         sns.heatmap(pivot, annot=True, fmt='.3f', cmap='viridis', ax=ax,
#                     cbar_kws={'label': 'œÅ(ŒõW)'})
#         ax.set_title('D) Radio Espectral de ŒõW')
#         ax.set_xlabel('Proporci√≥n de Trolls')
#         ax.set_ylabel('R√©gimen')
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'heatmaps.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: heatmaps.png")
    
#     def plot_correlation_matrix(self):
#         """Matriz de correlaciones"""
#         print("üìà Generando matriz de correlaciones...")
        
#         # Seleccionar variables num√©ricas clave
#         vars_of_interest = [
#             'mean_rangoFinal', 'mean_stdFinal', 'mean_NDI', 'mean_P2', 'mean_P4',
#             'mean_convTime', 'mean_rho_LW', 'prop_consenso',
#             'fracTrolls', 'lam', 'p'
#         ]
        
#         # Filtrar variables que existen
#         vars_available = [v for v in vars_of_interest if v in self.df.columns]
        
#         corr_data = self.df[vars_available].corr()
        
#         fig, ax = plt.subplots(figsize=(12, 10))
        
#         # Crear m√°scara para tri√°ngulo superior
#         mask = np.triu(np.ones_like(corr_data, dtype=bool))
        
#         sns.heatmap(corr_data, mask=mask, annot=True, fmt='.2f', 
#                     cmap='coolwarm', center=0, square=True, ax=ax,
#                     linewidths=1, cbar_kws={'label': 'Correlaci√≥n de Pearson'})
        
#         ax.set_title('Matriz de Correlaciones entre Variables Clave', 
#                      fontsize=14, fontweight='bold', pad=20)
        
#         # Rotar etiquetas para mejor lectura
#         plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
#         plt.setp(ax.get_yticklabels(), rotation=0)
        
#         plt.tight_layout()
#         plt.savefig(self.output_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
#         plt.close()
        
#         print(f"  ‚úì Guardado: correlation_matrix.png")

#==============================================================================
# SECCI√ìN 5: AN√ÅLISIS COMPARATIVO POR LAMBDA
#==============================================================================

    def lambda_analysis(self):
        """An√°lisis detallado del efecto de lambda"""
        print("="*70)
        print("AN√ÅLISIS DETALLADO DE LAMBDA (SUSCEPTIBILIDAD)")
        print("="*70 + "\n")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Efecto de Lambda (Susceptibilidad) en las Din√°micas', 
                     fontsize=16, fontweight='bold')
        
        # 1. Lambda vs Polarizaci√≥n por r√©gimen
        ax = axes[0, 0]
        for regime in ['desconectada', 'umbral', 'fuerte']:
            data = self.df[self.df['regimen'] == regime]
            lambda_groups = data.groupby('lam')['mean_NDI'].agg(['mean', 'std'])
            ax.errorbar(lambda_groups.index, lambda_groups['mean'], 
                       yerr=lambda_groups['std'], marker='o', capsize=5, 
                       linewidth=2, markersize=8, label=regime)
        
        ax.set_title('A) Lambda vs Polarizaci√≥n (NDI)')
        ax.set_xlabel('Lambda (Œª)')
        ax.set_ylabel('NDI (media ¬± std)')
        ax.legend(title='R√©gimen')
        ax.grid(True, alpha=0.3)
        
        # 2. Lambda vs Convergencia
        ax = axes[0, 1]
        for regime in ['desconectada', 'umbral', 'fuerte']:
            data = self.df[self.df['regimen'] == regime]
            lambda_groups = data.groupby('lam')['mean_convTime'].agg(['mean', 'std'])
            ax.errorbar(lambda_groups.index, lambda_groups['mean'],
                       yerr=lambda_groups['std'], marker='s', capsize=5,
                       linewidth=2, markersize=8, label=regime)
        
        ax.set_title('B) Lambda vs Tiempo de Convergencia')
        ax.set_xlabel('Lambda (Œª)')
        ax.set_ylabel('Tiempo (media ¬± std)')
        ax.legend(title='R√©gimen')
        ax.grid(True, alpha=0.3)
        
        # 3. Lambda vs Consenso
        ax = axes[1, 0]
        for trolls_cat in ['0%', '10%', '20%', '30%']:
            data = self.df[self.df['trolls_cat'] == trolls_cat]
            if len(data) > 0:
                lambda_groups = data.groupby('lam')['prop_consenso'].mean()
                ax.plot(lambda_groups.index, lambda_groups.values,
                       marker='D', linewidth=2, markersize=8, label=trolls_cat)
        
        ax.set_title('C) Lambda vs Proporci√≥n de Consenso')
        ax.set_xlabel('Lambda (Œª)')
        ax.set_ylabel('Proporci√≥n de Consenso')
        ax.legend(title='% Trolls')
        ax.grid(True, alpha=0.3)
        
        # 4. Lambda vs Rango Final
        ax = axes[1, 1]
        scatter = ax.scatter(self.df['lam'], self.df['mean_rangoFinal'],
                            c=self.df['trolls_pct'], cmap='plasma',
                            alpha=0.6, s=50, edgecolor='black', linewidth=0.5)
        ax.set_title('D) Lambda vs Rango Final')
        ax.set_xlabel('Lambda (Œª)')
        ax.set_ylabel('Rango Final de Opiniones')
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('% Trolls')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'lambda_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úì An√°lisis de lambda completado: lambda_analysis.png\n")

#==============================================================================
# SECCI√ìN 6: AN√ÅLISIS DE UBICACI√ìN DE TROLLS
#==============================================================================

    def location_analysis(self):
        """An√°lisis del efecto de la ubicaci√≥n de trolls"""
        print("="*70)
        print("AN√ÅLISIS DE UBICACI√ìN DE TROLLS (CENTRALIDAD)")
        print("="*70 + "\n")
        
        data_with_trolls = self.df[self.df['trolls'] > 0]
        
        if len(data_with_trolls) == 0:
            print("‚ö†Ô∏è  No hay datos con trolls para analizar ubicaci√≥n\n")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Efecto de la Ubicaci√≥n de Trolls (Centralidad)', 
                     fontsize=16, fontweight='bold')
        
        # 1. Ubicaci√≥n vs Polarizaci√≥n por r√©gimen
        ax = axes[0, 0]
        for regime in ['desconectada', 'umbral', 'fuerte']:
            data = data_with_trolls[data_with_trolls['regimen'] == regime]
            if len(data) > 0:
                loc_groups = data.groupby('loc_cat')['mean_NDI'].mean()
                ax.plot(loc_groups.index.astype(str), loc_groups.values,
                       marker='o', linewidth=2, markersize=10, label=regime)
        
        ax.set_title('A) Ubicaci√≥n vs Polarizaci√≥n (NDI)')
        ax.set_xlabel('Banda de Centralidad')
        ax.set_ylabel('NDI Medio')
        ax.legend(title='R√©gimen')
        ax.grid(True, alpha=0.3)
        
        # 2. Ubicaci√≥n vs Rango Final
        ax = axes[0, 1]
        sns.boxplot(data=data_with_trolls, x='loc_cat', y='mean_rangoFinal', ax=ax, palette='Set2')
        ax.set_title('B) Ubicaci√≥n vs Rango Final')
        ax.set_xlabel('Banda de Centralidad')
        ax.set_ylabel('Rango Final')
        ax.legend(title='R√©gimen', bbox_to_anchor=(1.05, 1))
        ax.grid(True, alpha=0.3, axis='y')
        
        # 3. Heatmap: Ubicaci√≥n x % Trolls
        ax = axes[1, 0]
        pivot = data_with_trolls.pivot_table(values='mean_NDI',
                                             index='loc_cat',
                                             columns='trolls_cat')
        sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,
                    cbar_kws={'label': 'NDI'})
        ax.set_title('C) NDI: Ubicaci√≥n √ó % Trolls')
        ax.set_xlabel('Proporci√≥n de Trolls')
        ax.set_ylabel('Banda de Centralidad')
        
        # 4. Ubicaci√≥n vs Consenso
        ax = axes[1, 1]
        loc_consensus = data_with_trolls.groupby(['loc_cat', 'trolls_cat'])['prop_consenso'].mean().unstack()
        loc_consensus.plot(kind='bar', ax=ax, width=0.8, colormap='tab10')
        ax.set_title('D) Ubicaci√≥n vs Proporci√≥n de Consenso')
        ax.set_xlabel('Banda de Centralidad')
        ax.set_ylabel('Proporci√≥n de Consenso')
        ax.legend(title='% Trolls', bbox_to_anchor=(1.05, 1))
        ax.grid(True, alpha=0.3, axis='y')
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'location_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úì An√°lisis de ubicaci√≥n completado: location_analysis.png\n")

#==============================================================================
# SECCI√ìN 7: INFORME EJECUTIVO
#==============================================================================

    def generate_executive_summary(self, hypothesis_results):
        """Genera informe ejecutivo en texto"""
        print("="*70)
        print("GENERANDO INFORME EJECUTIVO")
        print("="*70 + "\n")
        
        report_path = self.output_dir / 'executive_summary.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("INFORME EJECUTIVO: EXPERIMENTOS FRIEDKIN-JOHNSEN\n")
            f.write("="*70 + "\n\n")
            
            # 1. Resumen del experimento
            f.write("1. DISE√ëO EXPERIMENTAL\n")
            f.write("-" * 70 + "\n")
            f.write(f"   ‚Ä¢ Total de escenarios: {len(self.df)}\n")
            f.write(f"   ‚Ä¢ Tama√±o de red: n = {self.df['n'].iloc[0]}\n")
            f.write(f"   ‚Ä¢ Reg√≠menes de red: {', '.join(self.df['regimen'].unique())}\n")
            f.write(f"   ‚Ä¢ Proporciones de trolls: {sorted(self.df['trolls_pct'].unique())}%\n")
            f.write(f"   ‚Ä¢ Valores de lambda: {sorted(self.df['lam'].unique())}\n")
            f.write(f"   ‚Ä¢ Ubicaciones de trolls: {', '.join(self.df['loc'].unique())}\n\n")
            
            # 2. Hallazgos principales
            f.write("2. HALLAZGOS PRINCIPALES\n")
            f.write("-" * 70 + "\n\n")
            
            # Efecto del r√©gimen
            regime_effect = self.df.groupby('regimen')['mean_NDI'].mean()
            f.write(f"   A) EFECTO DEL R√âGIMEN DE CONECTIVIDAD\n")
            f.write(f"      ‚Ä¢ Desconectada: NDI = {regime_effect['desconectada']:.4f}\n")
            f.write(f"      ‚Ä¢ Umbral:       NDI = {regime_effect['umbral']:.4f}\n")
            f.write(f"      ‚Ä¢ Fuerte:       NDI = {regime_effect['fuerte']:.4f}\n")
            
            if hypothesis_results['H1_regime_polarization']['significant']:
                f.write(f"      ‚úì Efecto SIGNIFICATIVO (p < 0.05)\n")
            else:
                f.write(f"      ‚úó Efecto NO significativo\n")
            f.write("\n")
            
            # Efecto de trolls
            trolls_effect = self.df.groupby('trolls_pct')['mean_NDI'].mean()
            f.write(f"   B) EFECTO DE LA PROPORCI√ìN DE TROLLS\n")
            for pct in sorted(trolls_effect.index):
                f.write(f"      ‚Ä¢ {pct:.0f}% trolls: NDI = {trolls_effect[pct]:.4f}\n")
            
            if hypothesis_results['H2_trolls_polarization']['significant']:
                rho = hypothesis_results['H2_trolls_polarization']['rho']
                f.write(f"      ‚úì Correlaci√≥n SIGNIFICATIVA (œÅ = {rho:.3f}, p < 0.05)\n")
            else:
                f.write(f"      ‚úó Correlaci√≥n NO significativa\n")
            f.write("\n")
            
            # Efecto de lambda
            lambda_effect = self.df.groupby('lam')['mean_convTime'].mean()
            f.write(f"   C) EFECTO DE LAMBDA EN CONVERGENCIA\n")
            for lam in sorted(lambda_effect.index):
                f.write(f"      ‚Ä¢ Œª = {lam:.2f}: Tiempo = {lambda_effect[lam]:.2f}\n")
            
            if hypothesis_results['H3_lambda_convergence']['significant']:
                r = hypothesis_results['H3_lambda_convergence']['r']
                f.write(f"      ‚úì Correlaci√≥n SIGNIFICATIVA (r = {r:.3f}, p < 0.05)\n")
            else:
                f.write(f"      ‚úó Correlaci√≥n NO significativa\n")
            f.write("\n")
            
            # Ubicaci√≥n de trolls
            data_with_trolls = self.df[self.df['trolls'] > 0]
            if len(data_with_trolls) > 0:
                loc_effect = data_with_trolls.groupby('loc')['mean_rangoFinal'].mean()
                f.write(f"   D) EFECTO DE LA UBICACI√ìN DE TROLLS\n")
                for loc in ['low', 'mid', 'high']:
                    if loc in loc_effect.index:
                        f.write(f"      ‚Ä¢ {loc.capitalize()}: Rango = {loc_effect[loc]:.4f}\n")
                
                if hypothesis_results['H4_location_influence']['significant']:
                    f.write(f"      ‚úì Efecto SIGNIFICATIVO (p < 0.05)\n")
                else:
                    f.write(f"      ‚úó Efecto NO significativo\n")
                f.write("\n")
            
            # 3. M√©tricas de polarizaci√≥n
            f.write("3. M√âTRICAS DE POLARIZACI√ìN\n")
            f.write("-" * 70 + "\n")
            f.write(f"   ‚Ä¢ NDI medio:  {self.df['mean_NDI'].mean():.4f} ¬± {self.df['mean_NDI'].std():.4f}\n")
            f.write(f"   ‚Ä¢ P2 medio:   {self.df['mean_P2'].mean():.4f} ¬± {self.df['mean_P2'].std():.4f}\n")
            f.write(f"   ‚Ä¢ P4 medio:   {self.df['mean_P4'].mean():.2f} ¬± {self.df['mean_P4'].std():.2f}\n")
            f.write(f"   ‚Ä¢ Rango medio: {self.df['mean_rangoFinal'].mean():.4f} ¬± {self.df['mean_rangoFinal'].std():.4f}\n\n")
            
            # 4. Convergencia
            f.write("4. CONVERGENCIA\n")
            f.write("-" * 70 + "\n")
            f.write(f"   ‚Ä¢ Tiempo medio de convergencia: {self.df['mean_convTime'].mean():.2f} iteraciones\n")
            f.write(f"   ‚Ä¢ Proporci√≥n de consenso global: {self.df['prop_consenso'].mean():.2%}\n")
            f.write(f"   ‚Ä¢ Radio espectral ŒõW medio: {self.df['mean_rho_LW'].mean():.4f}\n\n")
            
            # 5. Recomendaciones
            f.write("5. RECOMENDACIONES Y CONCLUSIONES\n")
            f.write("-" * 70 + "\n")
            
            # An√°lisis autom√°tico de qu√© factores son m√°s importantes
            significant_factors = []
            if hypothesis_results['H1_regime_polarization']['significant']:
                significant_factors.append('r√©gimen de red')
            if hypothesis_results['H2_trolls_polarization']['significant']:
                significant_factors.append('proporci√≥n de trolls')
            if hypothesis_results['H3_lambda_convergence']['significant']:
                significant_factors.append('lambda (susceptibilidad)')
            if hypothesis_results['H4_location_influence']['significant']:
                significant_factors.append('ubicaci√≥n de trolls')
            
            if significant_factors:
                f.write(f"   ‚Ä¢ Factores significativos identificados: {', '.join(significant_factors)}\n\n")
            else:
                f.write(f"   ‚Ä¢ No se identificaron factores con efectos significativos fuertes.\n\n")
            
            # Recomendaciones espec√≠ficas
            f.write("   Recomendaciones para mitigar polarizaci√≥n:\n")
            
            if hypothesis_results['H2_trolls_polarization']['significant']:
                if hypothesis_results['H2_trolls_polarization']['rho'] > 0:
                    f.write("   1. Reducir la proporci√≥n de trolls en la red (correlaci√≥n positiva con polarizaci√≥n)\n")
            
            if hypothesis_results['H4_location_influence']['significant']:
                f.write("   2. Monitorizar trolls en posiciones de alta centralidad (mayor impacto)\n")
            
            if hypothesis_results['H3_lambda_convergence']['significant']:
                f.write("   3. Ajustar susceptibilidad (lambda) para optimizar convergencia\n")
            
            f.write("\n")
            f.write("="*70 + "\n")
            f.write("Fin del informe\n")
        
        print(f"‚úì Informe ejecutivo guardado: {report_path}\n")

#==============================================================================
# FUNCI√ìN PRINCIPAL
#==============================================================================

def main():
    """Funci√≥n principal para ejecutar el an√°lisis completo"""
    
    print("\n" + "="*70)
    print(" "*15 + "AN√ÅLISIS DE EXPERIMENTOS FRIEDKIN-JOHNSEN")
    print("="*70 + "\n")
    
    # Solicitar directorio de resultados
    import sys
    
    if len(sys.argv) > 1:
        results_dir = sys.argv[1]
    else:
        results_dir = input("Ingrese la ruta del directorio de resultados: ").strip()
    
    if not results_dir:
        print("‚ùå Error: Debe proporcionar un directorio de resultados")
        return
    
    try:
        # Inicializar analizador
        analyzer = FriedkinAnalyzer(results_dir)
        
        # 1. An√°lisis exploratorio
        desc_regime, desc_trolls, corr_matrix = analyzer.exploratory_analysis()
        
        # 2. Tests de hip√≥tesis
        hypothesis_results = analyzer.hypothesis_tests()
        
        # 3. Visualizaciones
        #analyzer.create_all_plots()
        
        # 4. An√°lisis espec√≠ficos
        analyzer.lambda_analysis()
        analyzer.location_analysis()
        
        # 5. Informe ejecutivo
        analyzer.generate_executive_summary(hypothesis_results)
        
        # Resumen final
        print("="*70)
        print("‚úì AN√ÅLISIS COMPLETADO")
        print("="*70)
        print(f"\nüìÅ Todos los resultados guardados en: {analyzer.output_dir}")
        print("\nArchivos generados:")
        print("  ‚Ä¢ descriptive_stats.txt")
        print("  ‚Ä¢ hypothesis_tests.txt")
        # print("  ‚Ä¢ executive_summary.txt")
        # print("  ‚Ä¢ main_effects.png")
        # print("  ‚Ä¢ interactions.png")
        # print("  ‚Ä¢ polarization_metrics.png")
        # print("  ‚Ä¢ convergence_analysis.png")
        # print("  ‚Ä¢ network_properties.png")
        # print("  ‚Ä¢ heatmaps.png")
        # print("  ‚Ä¢ correlation_matrix.png")
        # print("  ‚Ä¢ lambda_analysis.png")
        # print("  ‚Ä¢ location_analysis.png")
        print("\n" + "="*70 + "\n")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå Error: {e}")
        print("Verifique que la ruta del directorio sea correcta.\n")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()